{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ê–≤—Ç–æ—Ä: –ê–Ω–Ω–∞ –°–º–µ–ª–æ–≤–∞**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ—à–µ–Ω–∏–µ –¥–æ–º–∞—à–Ω–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è –∫ —É—Ä–æ–∫—É 8 \"–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1\n",
    "#### –û–±—É—á–∏—Ç—å –ª—é–±—É—é –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ IRIS –¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è PCA (2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã) –∏ –ø–æ—Å–ª–µ –Ω–µ–≥–æ. –°—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–∞–∫ –¥–æ–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n",
    "def get_accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "def standard_scale(x):\n",
    "    res = (x - x.mean(axis=0)) / x.std(axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∫–æ–≤–∞—Ä–∏–∞—Ü–∏—è\n",
    "def covariance(x, y):\n",
    "    return np.sum(x * y) / (len(x) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–ª–∞—Å—Å —É–∑–ª–∞\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # –∏–Ω–¥–µ–∫—Å –ø—Ä–∏–∑–Ω–∞–∫–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –≤–µ–¥–µ—Ç—Å—è —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø–æ—Ä–æ–≥–æ–º –≤ —ç—Ç–æ–º —É–∑–ª–µ\n",
    "        self.t = t  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞\n",
    "        self.true_branch = true_branch  # –ø–æ–¥–¥–µ—Ä–µ–≤–æ, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–µ–µ —É—Å–ª–æ–≤–∏—é –≤ —É–∑–ª–µ\n",
    "        self.false_branch = false_branch  # –ø–æ–¥–¥–µ—Ä–µ–≤–æ, –Ω–µ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–µ–µ —É—Å–ª–æ–≤–∏—é –≤ —É–∑–ª–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–ª–∞—Å—Å —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–≥–æ —É–∑–ª–∞ (–ª–∏—Å—Ç–∞)\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # –ø–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤\n",
    "        classes = {}  # —Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å \"–∫–ª–∞—Å—Å: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "            \n",
    "        # –Ω–∞–π–¥–µ–º –∫–ª–∞—Å—Å, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –∫–æ—Ç–æ—Ä–æ–≥–æ –±—É–¥–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –≤ —ç—Ç–æ–º –ª–∏—Å—Ç–µ –∏ –≤–µ—Ä–Ω–µ–º –µ–≥–æ    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–ª–∞—Å—Å –¥–µ—Ä–µ–≤–∞\n",
    "class Tree:\n",
    "    \n",
    "    def __init__(self, max_depth=100): # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞\n",
    "            \n",
    "        self.max_depth = max_depth\n",
    "        self.nodes = []\n",
    "        self.leaves = []\n",
    "        self.depth = 0\n",
    "        self.tree = None\n",
    "    \n",
    "    # –†–∞—Å—á–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è –î–∂–∏–Ω–∏\n",
    "    def gini(self, labels):\n",
    "        #  –ø–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤\n",
    "        classes = {}\n",
    "        for label in labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "\n",
    "        #  —Ä–∞—Å—á–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è\n",
    "        impurity = 1\n",
    "        for label in classes:\n",
    "            p = classes[label] / len(labels)\n",
    "            impurity -= p ** 2\n",
    "\n",
    "        return impurity\n",
    "    \n",
    "    # –†–∞—Å—á–µ—Ç –ø—Ä–∏—Ä–æ—Å—Ç–∞\n",
    "    def gain(self, left_labels, right_labels, root_gini):\n",
    "        # –¥–æ–ª—è –≤—ã–±–æ—Ä–∫–∏, —É—à–µ–¥—à–∞—è –≤ –ª–µ–≤–æ–µ –ø–æ–¥–¥–µ—Ä–µ–≤–æ\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "\n",
    "        return root_gini - p * self.gini(left_labels) - (1 - p) * self.gini(right_labels)\n",
    "    \n",
    "    # –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —É–∑–ª–µ\n",
    "    def split(self, data, labels, column_index, t):\n",
    "        left = np.where(data[:, column_index] <= t)\n",
    "        right = np.where(data[:, column_index] > t)\n",
    "\n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "\n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "    \n",
    "    # –†–µ–∞–ª–∏–∑—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –≤ —É–∑–ª–µ\n",
    "    def get_subsample(self, len_sample):\n",
    "        # –±—É–¥–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –Ω–µ —Å–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∞ –∏—Ö –∏–Ω–¥–µ–∫—Å—ã\n",
    "        sample_indexes = list(range(len_sample))\n",
    "\n",
    "        len_subsample = int(np.sqrt(len_sample))\n",
    "\n",
    "        subsample = np.random.choice(sample_indexes, size=len_subsample, replace=False)\n",
    "\n",
    "        return subsample\n",
    "    \n",
    "    # –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–∞–∏–ª—É—á—à–µ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è\n",
    "    def find_best_split(self, data, labels):\n",
    "        #  –æ–±–æ–∑–Ω–∞—á–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —É–∑–ª–µ\n",
    "        min_leaf_samples = 5\n",
    "\n",
    "        root_gini = self.gini(labels)\n",
    "\n",
    "        best_gain = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "\n",
    "        n_features = data.shape[1]\n",
    "\n",
    "        feature_subsample_indices = self.get_subsample(n_features) # –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "\n",
    "        for index in feature_subsample_indices:\n",
    "            # –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞, –∏—Å–∫–ª—é—á–∞—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è\n",
    "            t_values = np.unique([obj[index] for obj in data])\n",
    "\n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "                #  –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –≤ —É–∑–ª–µ –æ—Å—Ç–∞–µ—Ç—Å—è –º–µ–Ω–µ–µ 5 –æ–±—ä–µ–∫—Ç–æ–≤\n",
    "                if len(true_data) < min_leaf_samples or len(false_data) < min_leaf_samples:\n",
    "                    continue\n",
    "\n",
    "                current_gain = self.gain(true_labels, false_labels, root_gini)\n",
    "\n",
    "                #  –≤—ã–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –ø–æ–ª—É—á–∞–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "        return best_gain, best_t, best_index\n",
    "    \n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ —Å –ø–æ–º–æ—â—å—é —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "    def build_tree(self, data, labels):\n",
    "        gain, t, index = self.find_best_split(data, labels)\n",
    "        \n",
    "        #  –ë–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π 1 - –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é, –∫–æ–≥–¥–∞ –Ω–µ—Ç –ø—Ä–∏—Ä–æ—Å—Ç–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "        if gain == 0:\n",
    "            self.leaves.append(Leaf(data, labels))\n",
    "            return Leaf(data, labels)\n",
    " \n",
    "        #  –ë–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π 2 - –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é, –∫–æ–≥–¥–∞ –¥–æ—Å—Ç–∏–≥–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≥–ª—É–±–∏–Ω—ã –¥–µ—Ä–µ–≤–∞\n",
    "        if self.depth >= self.max_depth:\n",
    "            self.leaves.append(Leaf(data, labels))\n",
    "            return Leaf(data, labels)\n",
    "\n",
    "        self.depth += 1\n",
    "        \n",
    "        true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "\n",
    "        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å—Ç—Ä–æ–∏–º –¥–≤–∞ –ø–æ–¥–¥–µ—Ä–µ–≤–∞\n",
    "        true_branch = self.build_tree(true_data, true_labels)\n",
    "        false_branch = self.build_tree(false_data, false_labels)\n",
    "\n",
    "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–ª–∞—Å—Å —É–∑–ª–∞ —Å–æ –≤—Å–µ–º–∏ –ø–æ–¥–¥–µ—Ä–µ–≤—å—è–º–∏, —Ç–æ –µ—Å—Ç—å —Ü–µ–ª–æ–≥–æ –¥–µ—Ä–µ–≤–∞\n",
    "        self.nodes.append(Node(index, t, true_branch, false_branch))\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "    \n",
    "    def classify_object(self, obj, node):\n",
    "        #  –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é, –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏—Å—Ç–∞\n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.t:\n",
    "            return self.classify_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self.classify_object(obj, node.false_branch)\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        self.tree = self.build_tree(data, labels)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "        classes = []\n",
    "        for obj in data:\n",
    "            prediction = self.classify_object(obj, self.tree)\n",
    "            classes.append(prediction)\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–ª–∞—Å—Å —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees, # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–æ –¥–µ—Ä–µ–≤—å–µ–≤ \n",
    "                 max_depth=100, # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "                 max_leaves=200, # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç—å–µ–≤ –≤ –¥–µ—Ä–µ–≤—å—è—Ö\n",
    "                 min_leaf_objects=1):  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_leaves = max_leaves\n",
    "        self.min_leaf_objects = min_leaf_objects\n",
    "        self.forest = [] \n",
    "        self.train_accuracy = []\n",
    "        self.test_accuracy = []\n",
    "        self.train_roc = []\n",
    "        self.test_roc = []\n",
    "    \n",
    "    # –†–µ–∞–ª–∏–∑—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é ùëÅ –±—É—Ç—Å—Ç—Ä–∞–ø-–≤—ã–±–æ—Ä–æ–∫\n",
    "    def get_bootstrap(self, data, labels, N):\n",
    "        n_samples = data.shape[0] # —Ä–∞–∑–º–µ—Ä —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π\n",
    "        bootstrap = []\n",
    "\n",
    "        for i in range(N):\n",
    "            sample_index = np.random.randint(0, n_samples, size=n_samples)\n",
    "            b_data = data[sample_index]\n",
    "            b_labels = labels[sample_index]\n",
    "\n",
    "            bootstrap.append((b_data, b_labels))\n",
    "\n",
    "        return bootstrap\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        forest = []\n",
    "        bootstrap = self.get_bootstrap(data, labels, self.n_trees)\n",
    "\n",
    "        for b_data, b_labels in bootstrap:\n",
    "            new_tree = Tree(self.max_depth)\n",
    "            new_tree.fit(b_data, b_labels)\n",
    "            self.forest.append(new_tree)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ–º –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "    def tree_vote(self, data):\n",
    "        # –¥–æ–±–∞–≤–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –¥–µ—Ä–µ–≤—å–µ–≤ –≤ —Å–ø–∏—Å–æ–∫\n",
    "        predictions = []\n",
    "        for tree in self.forest:\n",
    "            \n",
    "            tree_vote = tree.predict(data)\n",
    "            predictions.append(tree_vote)\n",
    "\n",
    "        # —Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞\n",
    "        predictions_per_object = list(zip(*predictions))\n",
    "\n",
    "        # –≤—ã–±–µ—Ä–µ–º –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ —Ç–æ,\n",
    "        # –∑–∞ –∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–æ–≥–æ–ª–æ—Å–æ–≤–∞–ª–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "        voted_predictions = []\n",
    "        for obj in predictions_per_object:\n",
    "            voted_predictions.append(max(set(obj), key=obj.count))\n",
    "\n",
    "        return voted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∑–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç iris\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "target_names = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –æ—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "print(data.shape, target.shape)\n",
    "print(target_names)\n",
    "display(data[:5,:], target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],\n",
       "       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],\n",
       "       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ],\n",
       "       [-1.50652052,  0.09821729, -1.2833891 , -1.3154443 ],\n",
       "       [-1.02184904,  1.24920112, -1.34022653, -1.3154443 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º\n",
    "data = standard_scale(data)\n",
    "display(data[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (45, 4) (105,) (45,)\n"
     ]
    }
   ],
   "source": [
    "# –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "np.random.seed(0)\n",
    "shuffle_index = np.random.permutation(data.shape[0])\n",
    "X, y = data[shuffle_index], target[shuffle_index]\n",
    "\n",
    "# —Ä–∞–∑–¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 98.09523809523809\n"
     ]
    }
   ],
   "source": [
    "# –û–±—É—á–∏–º RandomForest –¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è PCA\n",
    "clf_before = RandomForest(n_trees=20)\n",
    "clf_before.fit(X_train, y_train)\n",
    "train_labels = clf_before.tree_vote(X_train)\n",
    "print(f'Train accuracy {get_accuracy_metric(y_train, train_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è:\n",
      "(437.77467247979905, array([ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654]))\n",
      "(137.1045707202107, array([-0.37741762, -0.92329566, -0.02449161, -0.06694199]))\n",
      "(22.01353133569727, array([-0.71956635,  0.24438178,  0.14212637,  0.63427274]))\n",
      "(3.107225464292895, array([ 0.26128628, -0.12350962, -0.80144925,  0.52359713]))\n"
     ]
    }
   ],
   "source": [
    "# –Ω–∞–π–¥–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "covariance_matrix = X.T @ X\n",
    "\n",
    "eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# —Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä)\n",
    "eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "\n",
    "# –∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print('–°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è:')\n",
    "for i in eig_pairs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏, –æ–ø–∏—Å—ã–≤–∞–µ–º–∞—è –∫–∞–∂–¥–æ–π –∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç \n",
      "[72.96244541329983, 22.85076178670178, 3.6689218892828785, 0.5178709107154825]\n",
      "–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º \n",
      "[ 72.96244541  95.8132072   99.48212909 100.        ]\n"
     ]
    }
   ],
   "source": [
    "# –æ—Ü–µ–Ω–∏–º –¥–æ–ª—é –¥–∏—Å–ø–µ—Ä—Å–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏.\n",
    "eig_sum = sum(eig_values)\n",
    "var_exp = [(i / eig_sum) * 100 for i in sorted(eig_values, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'–î–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏, –æ–ø–∏—Å—ã–≤–∞–µ–º–∞—è –∫–∞–∂–¥–æ–π –∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç \\n{var_exp}')\n",
    "\n",
    "# –∞ —Ç–µ–ø–µ—Ä—å –æ—Ü–µ–Ω–∏–º –∫—É–º—É–ª—è—Ç–∏–≤–Ω—É—é (—Ç–æ –µ—Å—Ç—å –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º—É—é) –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø—Ä–∏ —É—á–∏—Ç—ã–≤–∞–Ω–∏–∏ –∫–∞–∂–¥–æ–π –∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç\n",
    "print(f'–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º \\n{cum_var_exp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ø–µ—Ä–≤–∞—è –≥–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ—á—Ç–∏ 73% –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∞ –ø–µ—Ä–≤—ã–µ –¥–≤–µ –≤ —Å—É–º–º–µ - 95.8%. –í —Ç–æ –∂–µ –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω—è—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –≤—Å–µ–≥–æ 0.5% –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–±—Ä–æ–∂–µ–Ω–∞ –±–µ–∑ —Å—Ç—Ä–∞—Ö–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–µ—Ä—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –Ω–∞—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –ú—ã –æ—Ç–±—Ä–æ—Å–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–≤–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, –æ—Å—Ç–∞–≤–∏–≤ –ø–µ—Ä–≤—ã–µ –¥–≤–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ W:\n",
      " [[ 0.52106591 -0.37741762]\n",
      " [-0.26934744 -0.92329566]\n",
      " [ 0.5804131  -0.02449161]\n",
      " [ 0.56485654 -0.06694199]]\n"
     ]
    }
   ],
   "source": [
    "# –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä –≤–µ—Å–æ–≤ –∏–∑ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–µ—Ä–≤—ã–º –¥–≤—É–º –≥–ª–∞–≤–Ω—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º\n",
    "W = np.hstack([eig_pairs[i][1].reshape(4,1) for i in range(2)])\n",
    "\n",
    "print(f'–ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ W:\\n', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4676452 ,  0.44227159],\n",
       "       [ 0.56210831,  1.76472438],\n",
       "       [-2.44617739, -2.15072788],\n",
       "       [ 2.30243944, -0.42006558],\n",
       "       [-2.23284716, -0.22314807]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—É—é –º–∞—Ç—Ä–∏—Ü—É \"–æ–±—ä–µ–∫—Ç—ã-–ø—Ä–∏–∑–Ω–∞–∫–∏\"\n",
    "X_reduced = X.dot(W)\n",
    "X_reduced[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 2) (45, 2) (105,) (45,)\n"
     ]
    }
   ],
   "source": [
    "# —Ä–∞–∑–¥–µ–ª–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "X_train_reduced, X_valid_reduced, y_train_reduced, y_valid_reduced = train_test_split(X_reduced, y, test_size=0.3, random_state=42)\n",
    "print(X_train_reduced.shape, X_valid_reduced.shape, y_train_reduced.shape, y_valid_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 95.23809523809523\n"
     ]
    }
   ],
   "source": [
    "# –û–±—É—á–∏–º RandomForest –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è PCA\n",
    "clf_after = RandomForest(n_trees=20)\n",
    "clf_after.fit(X_train_reduced, y_train_reduced)\n",
    "train_labels_reduced = clf_after.tree_vote(X_train_reduced)\n",
    "print(f'Train accuracy {get_accuracy_metric(y_train_reduced, train_labels_reduced)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy before PCA: 91.11111111111111, Train: 98.09523809523809\n",
      "Valid accuracy after PCA: 95.55555555555556, Train: 95.23809523809523\n"
     ]
    }
   ],
   "source": [
    "# —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "test_labels = clf_before.tree_vote(X_valid)\n",
    "test_labels_reduced = clf_after.tree_vote(X_valid_reduced)\n",
    "print(f'Valid accuracy before PCA: {get_accuracy_metric(y_valid, test_labels)}, Train: {get_accuracy_metric(y_train, train_labels)}')\n",
    "print(f'Valid accuracy after PCA: {get_accuracy_metric(y_valid_reduced, test_labels_reduced)}, Train: {get_accuracy_metric(y_train_reduced, train_labels_reduced)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–æ–¥: –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è PCA –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–æ. –¢–∞–∫–∂–µ —É–º–µ–Ω—å—à–∏–ª–æ—Å—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
